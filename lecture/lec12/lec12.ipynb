{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7782e12c-f08a-4c94-a144-81a0baeb83e2",
   "metadata": {},
   "source": [
    "# Lecture 12: Data Preparation I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1896c152-4b51-499f-9f9f-a019052ad150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to save space, do a symbolic link to previous lecture's data\n",
    "!ln -sf ../lec11/data ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f3ca1a-de88-4928-bdfe-2c14deb6ff43",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## [review] Structural Transformation: From Relations to Matrices and Back\n",
    "- Matrix $\\rightarrow$ Relational works.\n",
    "- Relational $\\rightarrow$ Matrix sometimes works!\n",
    "- But how?\n",
    "\n",
    "To start, let's take our matrix in `mm.txt`, and load it into Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89df7e25-e979-4147-9c7b-1d685b6d03f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7571ed-20ca-4751-8f6a-6c91b20336a8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "mm = pd.read_csv('data/mm.txt', header=0)\n",
    "mm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3202db1-aae7-48a5-9835-594af348a1f8",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## [Review] What does an unpivot look like (Matrix -> Relational)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bfc658-47f3-42c5-8c63-51bcbff928cf",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "mm_melted = mm.melt(id_vars=['Year'])\n",
    "mm_melted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d004248d-3972-48bc-8dab-d1f8cd4d4c31",
   "metadata": {},
   "source": [
    "Thanks to the `id_var` parameter, the `Year` column is named and repeated for all other (variable=column name, value=value) elements in the row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304401ce-65fc-408c-92cc-217cc682aee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mm_melted[mm_melted['Year'] == 2002]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac5444a-9a2c-4d1a-98d7-1bb0ef23da57",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## PIVOT(UNPIVOT) = ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa6b449-e5bb-4868-b398-6a285537473c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# how do we get back to something that resembles the original matrix?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb83c341-8bbb-484f-9232-85f317329cb2",
   "metadata": {},
   "source": [
    "# Data Unboxing, Part I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c1a629-1d30-4a33-ab4c-64a34e805f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "!du -h data/*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c951af-fd6d-4b62-a35e-f98212605f49",
   "metadata": {},
   "source": [
    "What category of data is the file below? Any observations about the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c97d22-703a-4d50-9296-4d84e92705b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -c 1024 data/jc1.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fe53da-692c-4fa7-b638-98d24c4594b0",
   "metadata": {},
   "source": [
    "**Exercise**: What do you see this time? Category? Interesting features of the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071800dc-0b9d-4aa9-831b-8612e5660012",
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -c 1024 data/jq2.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7204251-2e8e-43ab-9897-c60227b066a3",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Data Unboxing, Part II"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d22ae0-148f-41ba-95ee-0c6410b53a59",
   "metadata": {},
   "source": [
    "Let's explore the first file here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92be082-84da-4774-b914-7f219d61eb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -c 1024 data/jc1.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f3de6e-96dd-4c3c-8fa0-275416b37005",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import pandas as pd\n",
    "\n",
    "jc1 = pd.read_csv('data/jc1.txt', header=0, sep=',')\n",
    "jc1.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcba815c-59db-46d5-867f-b728f769fa65",
   "metadata": {},
   "source": [
    "What data types are each column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5031c0-b6c5-403b-86c3-c4594586f541",
   "metadata": {},
   "outputs": [],
   "source": [
    "jc1.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a597fb73-9c3d-47d0-a978-2c70bb87db7b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Currently, we're working with objects, because of how pandas read in the dtypes. Let's try to modify some scores here for contestants to make them numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770424b6-bb75-4202-abdf-ef81e6547df2",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "jc1.columns\n",
    "for col in jc1.columns:\n",
    "    if '_score' in col:\n",
    "        jc1[col] = jc1[col].map(lambda x: float(x.strip('$')) if type(x) == str else np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80d57d3-0f5c-4d7e-81ca-522c9a083818",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What are our dtypes now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690b3851-0d1c-4f2f-be87-48744d7669c6",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "jc1.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcee6e6-67dc-4e26-a0b6-670363d6af17",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Can we visualize our contestant winnings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15df92c1-05bf-4c99-935e-e3cbd355fd13",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "jc1.hist(column='contestant1_score')\n",
    "jc1.hist(column='contestant2_score')\n",
    "jc1.hist(column='contestant3_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a08d070-8741-4e21-aba4-66a81cedf661",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# CNRFC-NOAA Rainfall Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3462a9-e95d-46ac-89fd-063c5b5d9a0b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* There are four data files tied to the scrape of rainfall data from the NOAA (National Oceanic and Atmospheric Administration) [link](https://www.cnrfc.noaa.gov/monthly_precip_2020.php).\n",
    "* This was compiled by visiting each annual website of monthly precipitation by regions in the California Nevada River Forecast Center (CNRFC) area.\n",
    "* For more details on how to make this dataset yourself, check out the `rainfallscrape` folder. You may need to install additional Python packages via `pip -r rainfallscrape/requirements.txt`.\n",
    "\n",
    "Let's unbox this data too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fb451e-f285-481c-a0da-9a83a0cec29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lh data/m*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04228afe-75cb-4ebb-abd1-04e036fc380d",
   "metadata": {},
   "source": [
    "All of these files *look* rectangular. **What data model does each follow, structurally?**\n",
    "\n",
    "Analyze the first few lines of each file in order below. Remember to adjust `-n` number of lines as needed.\n",
    "1. `mm.txt`\n",
    "2. `mmp.txt`\n",
    "3. `mmr.txt`\n",
    "4. `mpf.txt` - may need to look at first 20 lines here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1deaa829-dd84-4cf2-a993-8d6bca09c873",
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -n 20 data/mpf.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2bc202-6827-4490-b46a-ae79d336d24b",
   "metadata": {},
   "source": [
    "## Fulfilling Structural Transformation Requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525d64e0-2ae3-4302-a606-92251e5f0c1b",
   "metadata": {},
   "source": [
    "Let's start from the long (tidy, relational) file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17b156a-5289-46de-b0fd-a61d5cce8260",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.min_rows', 15) # changes truncated view in pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b0cbe9-05c0-4f25-8311-2c02c3dc1edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmr = pd.read_csv('data/mmr.txt')\n",
    "mmr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c54043a-cb58-4159-8f83-bcdb30bbd6e6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A data analyst asks for just the precipitation grouped by year and month, with no location data. **How do we do this?**\n",
    "* What are they asking for? This isn't intuitive, because we have location data as well. What do we do?\n",
    "* How do we pivot the data into year x month form?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f4368e-fc96-411b-bb6b-8bada6e0f534",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# fill in here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223130ef-ebc1-45e9-9584-58309ea3676c",
   "metadata": {},
   "source": [
    "<br/><br/><br/><br/>\n",
    "\n",
    "### solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a56e2c-2064-4287-9b24-8a6cfc675eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmr_grouped = mmr_grouped.reset_index()\n",
    "mmr_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bf1d0a-861f-46f1-adf2-d4bfdfa6a1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmr_pivoted = mmr_grouped.pivot(index='Year', columns='Month')\n",
    "mmr_pivoted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31164e8-bd2c-4fed-a7ef-bafed4718f13",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Scalar Functions and Query Plans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50555b0a-b8f6-4210-88d7-d23b9a156f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## we'll use the Lahman baseball database in our examples today.\n",
    "## replace the database connection with a database of your own!\n",
    "%reload_ext sql\n",
    "%sql postgresql://localhost:5432/baseball\n",
    "%config SqlMagic.displaylimit = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50f4a8f-ee66-4c31-bf14-73cc686aaacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "WITH yearnum AS\n",
    "  (SELECT yearid, (yearid % 100) as year\n",
    "     FROM batting\n",
    "  )\n",
    "SELECT yearid, CONCAT('''', LPAD(year::text, 2, '0')) as year\n",
    "  FROM yearnum\n",
    " LIMIT 5;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2333a67a-d66f-4cb6-a61d-03e0a73b53b3",
   "metadata": {},
   "source": [
    "Let's analyze the below query (we've flattened it for convenience):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb17df72-4ed0-4ca4-8317-f27bf8d4efaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "EXPLAIN (VERBOSE true)\n",
    "SELECT yearid,\n",
    "       CONCAT('''', LPAD((yearid % 100)::text, 2, '0')) AS year\n",
    "FROM batting;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adecb922-2f1a-417e-a153-5a3a06d15e5d",
   "metadata": {},
   "source": [
    "What if scalar functions mention multiple tables?\n",
    "\n",
    "The below query computes an arbitrary statistic for pitchers:\n",
    "* 1 point for every strikeout they throw as pitcher\n",
    "* â€“1 for every point they themselves struck out as batter\n",
    "\n",
    "If the notebook-like output is hard to read, try out the query in `psql`. Note that notebooks don't preserve whitespace when displaying dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22b2d8e-baf2-4c96-afbe-d82c492a77e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "EXPLAIN (VERBOSE true)\n",
    "SELECT p.playerid, p.so - b.so\n",
    "  FROM pitching p\n",
    "  INNER JOIN batting b\n",
    "  ON p.playerid=b.playerid;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83dd3bf1-5408-427a-85ea-5e64430dac4e",
   "metadata": {},
   "source": [
    "## [Extra] Recreating the CNRFC-NOAA data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3729d242-d265-419e-b8c7-266e5dd8b04e",
   "metadata": {},
   "source": [
    "* There are four data files tied to the scrape of rainfall data from the NOAA (National Oceanic and Atmospheric Administration) [link](https://www.cnrfc.noaa.gov/monthly_precip_2020.php).\n",
    "* This was compiled by visiting each annual website of monthly precipitation by regions in the California Nevada River Forecast Center (CNRFC) area.\n",
    "* For more details on how to make this dataset yourself, check out the `rainfallscrape` folder. You may need to install additional Python packages via `pip -r rainfallscrape/requirements.txt`. We'll assume you've already run `simple_scrape.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19948782-74df-4fab-9cbe-20811973db8f",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "!head -c 4096 data/mpf.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1efc905-fd55-4881-9112-e901e1794830",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Messy! You can play in bash or pandas if you like. Let's clean this up a bit. Firstly, we note that the structure of the file is a bit off. It's hard to read multiple dataframes from a single CSV like this...so let's try to write multiple files and concatenate a df.\n",
    "\n",
    "- Going to iterate through the lines in this files...\n",
    "- Identify the files with names of locations\n",
    "- print the filenames transformed to see what it's like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51c8cfa-aab9-41b0-95a8-7be7615a5e35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "curr_file = None\n",
    "with open('data/mpf.txt') as f:\n",
    "    for line in f.readlines():\n",
    "        splits = line.split(', ')\n",
    "        if len(splits) == 2:\n",
    "            print(splits[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf56d62b-36f3-4656-8637-8c50b85dc327",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Okay, first, let's create some files; one for each segment. And let's rename them into something more conventional. \n",
    "\n",
    "- Going to iterate through the lines in this files...\n",
    "- Identify the files with names of locations\n",
    "- print the filenames transformed to see what it's like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddb7072-011c-4107-8616-2fda9749796f",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "curr_file = None\n",
    "with open('lec12_data/mpf.txt') as f:\n",
    "    for num, line in enumerate(f.readlines()):\n",
    "        splits = line.split(', ')\n",
    "        if len(splits) == 2:\n",
    "            print(splits[1].strip(\" '\\n \").replace('...', '-').replace(' ', '_'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f1d86d-9331-46e9-8a66-3a506ec0811e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "That's probably more of what we want! Now, let's actually write our new files..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41498a4-02d0-4c0a-a551-ae9a652d8571",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "curr_file = None\n",
    "with open('data/mpf.txt') as master_file:\n",
    "    for line in master_file.readlines():\n",
    "        splits = line.split(', ')\n",
    "        if len(splits) == 2:\n",
    "            if curr_file is not None:\n",
    "                curr_file.close()\n",
    "            filename = splits[0] + '_' + splits[1].strip(\" '\\n \")\n",
    "            filename = filename.replace('...', '-')\n",
    "            filename = filename.replace(' ', '_')\n",
    "            curr_file = open('data/subfiles/' + filename + '.txt', 'w')\n",
    "        curr_file.write(line)\n",
    "curr_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea06230-c141-4810-897a-3cca1d9ed6ae",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now, let's read these files into a dataframe...and we'll need to do a lot of preprocessing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b447eba-23fd-4f0a-86d6-2e296deef85e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "mpf = pd.DataFrame()\n",
    "parent_dir = os.getcwd() + '/data/subfiles/'\n",
    "for filename in os.listdir(parent_dir):\n",
    "    # read from the first header. not the second!\n",
    "    region_df = pd.read_csv(parent_dir + '/' + filename, header=1)\n",
    "    # BE CAREFUL! Let's rename our schema...because right now, this is problematic.\n",
    "    # The first column is just labeled as the year itself (e.g. 2007). Not 'Year'.\n",
    "    region_df = region_df.rename(columns={filename.split('_')[0]: 'Year'})\n",
    "    mpf = mpf.append(region_df)\n",
    "mpf = mpf.sort_values('Year')\n",
    "mpf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a741ac40-9802-46b3-973b-58824423552b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now, let's figure out what our data looks like in Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66faef70-78cf-4733-a504-25c24461e19b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "mpf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc04f2b-dcd4-408f-823a-660f6c4ae0a0",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "mpf.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa97d943-ae65-4d8e-8909-a40515f3ef98",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's rename our columns!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c679b2f3-e149-4d00-9e17-cac5cb801d05",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "col_set = {}\n",
    "for column in mpf.columns:\n",
    "    if column != 'Year':\n",
    "        col_set.update({column: column.strip(\" '\")})\n",
    "mpf = mpf.rename(columns=col_set)\n",
    "mpf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf10685-9271-4461-8838-414ae2a00e93",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Let's remove the Ms and replace them with NaNs, and strip the quotes\n",
    "import math\n",
    "def _process_data(x):\n",
    "    if type(x) == float:\n",
    "        return x\n",
    "    if type(x) != str and math.isnan(x):\n",
    "        return np.nan\n",
    "    x = x.strip(\"' \")\n",
    "    if x == 'M' or x == 'NA':\n",
    "        return np.nan\n",
    "    else:\n",
    "        return float(x)\n",
    "\n",
    "mpf = mpf[mpf['Year'] == 2002]\n",
    "for col in mpf.columns:\n",
    "    if col in [\"ID\", \"Location\"]:\n",
    "        print(col)\n",
    "        mpf[col] = mpf[col].map(lambda x: str(x).strip(\"'\"))\n",
    "    elif col != 'Year':\n",
    "        mpf[col] = mpf[col].map(lambda x: _process_data(x))\n",
    "mpf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
